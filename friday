
<div class="panel-heading">
        <h4><b>11:45 - 12:30</b> Jan K&#345;et&iacute;nsk&yacute; (Technical University of Munich) <i>Fast learning of small strategies</i></h4>
        <button type="button" class="btn btn-default" data-toggle="collapse" data-target="#kretinsky" data-parent="#accordion">((more))</button>
</div>













<div id="kretinsky" class="panel-collapse collapse">
    <div class="panel-body">

        <dl class="dl-horizontal">
        <dt>Speaker:</dt>
        <dd><a href="https://www7.in.tum.de/~kretinsk/">Jan K&#345;et&iacute;nsk&yacute;</a>, Technical University of Munich</dd>

        <dt>Title:</dt>
        <dd>Fast learning of small strategies</dd>

        <dt>Abstract:</dt>
        <dd>
        In verification, precise analysis is required, but the algorithms usually suffer from scalability issues. In machine learning, scalability is achieved, but with only very weak guarantees. 
        We show how to merge the two philosophies and profit from both. In this talk, we focus on analysing Markov decision processes. 
        We show how to learn ε-optimal strategies fast and how to represent them concisely so that some understanding of the behaviour and debugging information can be extracted. 
        </dd>
        </dl>
    </div>
</div>

<div class="panel-heading">
        <h4><b>14:45 - 15:30</b> Richard Evans (DeepMind) <i>Learning Explanatory Rules from Noisy Data</i></h4>
        <button type="button" class="btn btn-default" data-toggle="collapse" data-target="#evans" data-parent="#accordion">((more))</button>
</div>

<div id="evans" class="panel-collapse collapse">
    <div class="panel-body">

        <dl class="dl-horizontal">
        <dt>Speaker:</dd>
        <dd>Richard Evans</a>, Staff Research Scientist, DeepMind</dd>

        <dt>Title:</dt>
        <dd>Learning Explanatory Rules from Noisy Data</dd>

        <dt>Abstract:</dt>
        <dd>
        Artificial Neural Networks are powerful function approximators capable of modelling solutions to a wide variety of problems, both supervised and unsupervised. 
        As their size and expressivity increases, so too does the variance of the model, yielding a nearly ubiquitous overfitting problem. 
        Although mitigated by a variety of model regularisation methods, the common cure is to seek large amounts of training data—which is not necessarily easily obtained—that sufficiently approximates the data distribution of the domain we wish to test on. In contrast, logic programming methods such as Inductive Logic Programming offer an extremely data-efficient process by which models can be trained to reason on symbolic domains. However, these methods are unable to deal with the variety of domains neural networks can be applied to: they are not robust to noise in or mislabelling of inputs, and perhaps more importantly, cannot be applied to non-symbolic domains where the data is ambiguous, such as operating on raw pixels. In this paper, we propose a Differentiable Inductive Logic framework (∂ILP), which can not only solve tasks which traditional ILP systems are suited for, but shows a robustness to noise and error in the training data which ILP cannot cope with. Furthermore, as it is trained by back-propagation against a likelihood objective, it can be hybridised by connecting it with neural networks over ambiguous data in order to be applied to domains which ILP cannot address, while providing data efficiency and generalisation beyond what neural networks on their own can achieve.
        </dd>
        </dl>
    </div>
</div>

</div>

<h4>Coffee break</h4>

                        </div>
                </div>
        </div>
</section>

<section id="friday_morning">
        <div class="container">
                <div class="row">
                        <div class="col-md-12">
                                <h2>Friday 12th morning</h2>

<div id="accordion" class="panel-group">

<div class="panel panel-default">

<h3><b>9:00–10:30</b> Probabilistic programming I</h3>

<div class="panel-heading">
        <h4><b>9:00 - 9:45</b> Jane Hillston (University of Edinburgh) <i>Integrating Inference with Stochastic Process Algebra Models</i></h4>
        <button type="button" class="btn btn-default" data-toggle="collapse" data-target="#hillston" data-parent="#accordion">((more))</button>
</div>

<div id="hillston" class="panel-collapse collapse">
    <div class="panel-body">

        <dl class="dl-horizontal">
        <dt>Speaker:</dd>
        <dd><a href="http://homepages.inf.ed.ac.uk/jeh/">Jane Hillston</a>, School of Informatics, University of Edinburgh</dd>

        <dt>Title:</dt>
        <dd>Integrating Inference with Stochastic Process Algebra Models</dd>

        <dt>Abstract:</dt>
        <dd>
        ProPPA is a probabilistic programming language for continuous-time dynamical systems, developed as an extension of the stochastic process algebra Bio-PEPA. It offers a high-level syntax for describing systems of interacting components with stochastic behaviours where some of the parameters are unknown. Such systems occur in many and diverse fields, including biology, ecology and urban transport, and while their modelling and analysis are important, existing methodologies are often not accessible to non-experts, in addition to being tailor-made rather than generally applicable. In particular, parameter learning can be of crucial significance but is a difficult problem due to the complexity of the underlying probabilistic model --- namely, the continuous time setting and the fast-growing number of states.
<br/>
The purpose of the ProPPA framework is to facilitate both the description of these systems and the process of inference, by automating the application of appropriate algorithms. The language is equipped with different parameter inference methods, including a novel MCMC scheme which employs a random truncation strategy to obtain unbiased likelihood estimates. This method is particularly suited to systems with infinite state-spaces, which were previously not manageable without imposing an ad-hoc truncation. Other methods include a naive Approximate Bayesian Computation algorithm and a sampler based on a continuous approximation of the state-space.
        </dd>
        </dl>
    </div>
</div>

</div>

<h4>Coffee break</h4>

<div class="panel panel-default">

<h3><b>11:00–12:30</b> Probabilistic programming II</h3>

<div class="panel-heading">
        <h4><b>11:00 - 11:45</b> Joost-Pieter Katoen (RWTH Aachen University) <i>Bayesian Inference by Program Verification</i></h4>
        <button type="button" class="btn btn-default" data-toggle="collapse" data-target="#katoen" data-parent="#accordion">((more))</button>
</div>

<div id="katoen" class="panel-collapse collapse">
    <div class="panel-body">

        <dl class="dl-horizontal">
        <dt>Speaker:</dd>
        <dd><a href="http://www-i2.informatik.rwth-aachen.de/~katoen/">Joost-Pieter Katoen</a>, RWTH Aachen University</dd>

        <dt>Title:</dt>
        <dd>Bayesian Inference by Program Verification</dd>

        <dt>Abstract:</dt>
        <dd>
In this talk, I will give a perspective on inference in Bayes' networks
(BNs) using program verification. I will argue how weakest precondition
reasoning a la Dijkstra can be used for exact inference (and more). As
exact inference is NP-complete, inference is typically done by means of
simulation. I will show how by means of wp-reasoning exact expected
sampling times of BNs can be obtained in a fully automated fashion. An
experimental evaluation on BN benchmarks demonstrates that very large
expected sampling times (in the magnitude of millions of years) can be
inferred within less than a second. This provides a means to decide
whether sampling-based methods are appropriate for a given BN.
        </dd>
        </dl>
    </div>
</div>

<div class="panel-heading">
        <h4><b>11:45 - 12:30</b> Sam Staton (Oxford) <i>Denotational validation of higher-order Bayesian inference</i></h4>
        <button type="button" class="btn btn-default" data-toggle="collapse" data-target="#staton" data-parent="#accordion">((more))</button>
</div>

<div id="staton" class="panel-collapse collapse">
    <div class="panel-body">

        <dl class="dl-horizontal">
        <dt>Speaker:</dd>
        <dd><a href="http://www.cs.ox.ac.uk/people/samuel.staton/main.html">Sam Staton</a>, University of Oxford</dd>

        <dt>Title:</dt>
        <dd>Denotational validation of higher-order Bayesian inference</dd>

        <dt>Abstract:</dt>
        <dd>
        We present a modular semantic account of Bayesian inference algorithms for probabilistic programming languages, as used in data science and machine learning. Sophisticated inference algorithms are often explained in terms of composition of smaller parts. However, neither their theoretical justification nor their implementation reflects this modularity. We show how to conceptualise and analyse such inference algorithms as manipulating intermediate representations of probabilistic programs using higher-order functions and inductive types, and their denotational semantics. Semantic accounts of continuous distributions use measurable spaces. However, our use of higher-order functions presents a substantial technical difficulty: it is impossible to define a measurable space structure over the collection of measurable functions between arbitrary measurable spaces that is compatible with standard operations on those functions, such as function application. We overcome this difficulty using quasi-Borel spaces, a recently proposed mathematical structure that supports both function spaces and continuous distributions. We define a class of semantic structures for representing probabilistic programs, and semantic validity criteria for transformations of these representations in terms of distribution preservation. We develop a collection of building blocks for composing representations. We use these building blocks to validate common inference algorithms such as Sequential Monte Carlo and Markov Chain Monte Carlo. To emphasize the connection between the semantic manipulation and its traditional measure theoretic origins, we use Kock's synthetic measure theory. We demonstrate its usefulness by proving a quasi-Borel counterpart to the Metropolis-Hastings-Green theorem.
        </dd>
        </dl>
    </div>
</div>

</div>

</div>

<h4>Lunch</h4>

                                </div>
                        </div>
                </div>
        </div>
</section>

<section id="programme_friday_afternoon">
        <div class="orangeback">
                <div class="container">
                        <div class="row">
                                <div class="col-md-12">
                                </div>
                        </div>
                </div>
        </div>
</section>

<section id="friday_afternoon">
        <div class="container">
                <div class="row">
                        <div class="col-md-12">
                                <h2>Friday 12th afternoon</h2>

<div id="accordion" class="panel-group">

<div class="panel panel-default">

<h3><b>14:00–15:30</b> Neural networks</h3>


<div class="panel-heading">
        <h4><b>14:45 - 15:30</b> Tim Rockt&auml;schel (University of Oxford) <i>End-to-End Differentiable Proving</i></h4>
        <button type="button" class="btn btn-default" data-toggle="collapse" data-target="#rockt" data-parent="#accordion">((more))</button>
</div>

<div id="rockt" class="panel-collapse collapse">
    <div class="panel-body">

        <dl class="dl-horizontal">
        <dt>Speaker:</dd>
        <dd><a href="https://rockt.github.io/">Rockt&auml;schel</a>, University of Oxford</dd>

        <dt>Title:</dt>
        <dd>End-to-End Differentiable Proving</dd>

        <dt>Abstract:</dt>
        <dd>
We introduce neural networks for end-to-end differentiable proving of queries to knowledge bases by operating on dense vector representations of symbols. These neural networks are constructed recursively by taking inspiration from the backward chaining algorithm as used in Prolog. Specifically, we replace symbolic unification with a differentiable computation on vector representations of symbols using a radial basis function kernel, thereby combining symbolic reasoning with learning subsymbolic vector representations. By using gradient descent, the resulting neural network can be trained to infer facts from a given incomplete knowledge base. It learns to (i) place representations of similar symbols in close proximity in a vector space, (ii) make use of such similarities to prove queries, (iii) induce logical rules, and (iv) use provided and induced logical rules for multi-hop reasoning. We demonstrate that this architecture outperforms ComplEx, a state-of-the-art neural link prediction model, on three out of four benchmark knowledge bases while at the same time inducing interpretable function-free first-order logic rules.
        </dd>
        </dl>
    </div>
</div>

<h4>Coffee break</h4>

<h3><b>16:00–17:00</b> Concluding remarks and perspectives</h3>

</div>

</div>

                        </div>
                </div>
        </div>
</section>

